{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import tensorflow as tf \r\n",
    "from tensorflow import keras\r\n",
    "from data_loader import DataLoader\r\n",
    "import random\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "random.seed(1)\r\n",
    "np.random.seed(1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def split_train_test(images, masks, validation_split=0.8):\r\n",
    "    split_index = int(images.shape[0] * 0.8)\r\n",
    "    return images[0:split_index], masks[0:split_index], images[split_index:], masks[split_index:]\r\n",
    "\r\n",
    "def normalize(images, masks):\r\n",
    "    images = images / 255\r\n",
    "    masks = (masks > 0).astype(float)\r\n",
    "    return images, masks"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "raw_images, raw_masks = DataLoader().get_dataset()\r\n",
    "norm_images, norm_masks = normalize(raw_images, raw_masks)\r\n",
    "\r\n",
    "train_img, train_msk, test_img, test_msk = split_train_test(norm_images, norm_masks)\r\n",
    "\r\n",
    "train_img.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "valid_data = np.array( (test_img, test_msk) )\r\n",
    "valid_data.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## HYPERPARAMETERS"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "image_size = 512\r\n",
    "train_path = 'src/dataset_preview/train/'\r\n",
    "EPOCHS = 5\r\n",
    "BATCH_SIZE = 2\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualization "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "r = 1 #random.randint(0, len(train_img.shape) - 1)\r\n",
    "fig = plt.figure()\r\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\r\n",
    "ax = fig.add_subplot(1,2,1)\r\n",
    "ax.imshow(train_img[r], cmap='gray')\r\n",
    "ax1 = fig.add_subplot(1,2,2)\r\n",
    "ax1.imshow(train_msk[r], cmap='gray')\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutional Blocks"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def down_block(x, filters, kernel_size=(3,3), padding=\"same\", strides=1):\r\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation='relu')(x)\r\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation='relu')(c)\r\n",
    "\r\n",
    "    p = keras.layers.MaxPool2D((2,2), (2,2))(c)\r\n",
    "    return c, p \r\n",
    "\r\n",
    "def up_block(x, skip, filters, kernel_size=(3,3), padding=\"same\", strides=1):\r\n",
    "    up_sampling = keras.layers.UpSampling2D((2,2))(x)\r\n",
    "    concat = keras.layers.Concatenate()([up_sampling, skip])\r\n",
    "\r\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation='relu')(concat)\r\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation='relu')(c)\r\n",
    "\r\n",
    "    return c\r\n",
    "\r\n",
    "def bottleneck(x, filters, kernel_size=(3,3), padding=\"same\", strides=1):\r\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation='relu')(x)\r\n",
    "    c = keras.layers.Conv2D(filters, kernel_size, padding=padding, strides=strides, activation='relu')(c)\r\n",
    "\r\n",
    "    return c"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## UNet Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def UNet():\r\n",
    "    feature_maps = [64,128,256, 512, 1024]\r\n",
    "    inputs = keras.layers.Input( (image_size, image_size, 1) )\r\n",
    "\r\n",
    "    pool_0 = inputs\r\n",
    "    conv_1, pool_1 = down_block(pool_0, feature_maps[0]) #512 -> 256\r\n",
    "    conv_2, pool_2 = down_block(pool_1, feature_maps[1]) #256 -> 128 \r\n",
    "    conv_3, pool_3 = down_block(pool_2, feature_maps[2]) #128 -> 64\r\n",
    "    conv_4, pool_4 = down_block(pool_3, feature_maps[3]) #64 -> 32\r\n",
    "\r\n",
    "    bn = bottleneck(pool_4, feature_maps[4])\r\n",
    "\r\n",
    "    ups_1 = up_block(bn, conv_4, feature_maps[3]) #32 -> 64\r\n",
    "    ups_2 = up_block(ups_1, conv_3, feature_maps[2]) #64 -> 128\r\n",
    "    ups_3 = up_block(ups_2, conv_2, feature_maps[1]) #128 -> 256\r\n",
    "    ups_4 = up_block(ups_3, conv_1, feature_maps[0]) #256 -> 512\r\n",
    "\r\n",
    "    outputs = keras.layers.Conv2D(1, (1,1), padding='same', activation='sigmoid')(ups_4)\r\n",
    "\r\n",
    "    model = keras.models.Model(inputs, outputs)\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def jaccard_distance(y_true, y_pred, smooth=100):\r\n",
    "    intersection = keras.backend.sum(keras.backend.abs(y_true * y_pred), axis=-1)\r\n",
    "    sum_ = keras.backend.sum(keras.backend.square(y_true), axis = -1) + keras.backend.sum(keras.backend.square(y_pred), axis=-1)\r\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\r\n",
    "    return (1 - jac)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = UNet()\r\n",
    "\r\n",
    "model.compile(optimizer='adam', loss=jaccard_distance, metrics=['acc'])\r\n",
    "print(model.summary())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "v_data = (test_img, test_msk)\r\n",
    "v_data"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "train_steps = len(train_img)\r\n",
    "test_steps = len(test_img)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "model.fit(x=train_img, y=train_msk, batch_size=BATCH_SIZE , epochs=2, validation_data=v_data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save_weights('UNetW1.h5')\r\n",
    "\r\n",
    "result = model.predict(test_img)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "r = 1\r\n",
    "\r\n",
    "res = (result > 0.175).astype(float)\r\n",
    "print(type(result[r]), np.mean(res[r]))\r\n",
    "\r\n",
    "fig = plt.figure()\r\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\r\n",
    "ax = fig.add_subplot(1,2,1)\r\n",
    "ax.set_title('Ground truth')\r\n",
    "ax.imshow(test_msk[r], cmap='gray')\r\n",
    "\r\n",
    "\r\n",
    "ax1 = fig.add_subplot(1,2,2)\r\n",
    "ax1.set_title('Predicted mask')\r\n",
    "ax1.imshow(res[r], cmap='gray')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test if model works on cpu"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import train_gpu \r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "test_train = train.Trainer()\r\n",
    "test_train.load_data()\r\n",
    "test_train.build_model()\r\n",
    "# test_train.train()\r\n",
    "# test_train.save()\r\n",
    "\r\n",
    "test_train.model.load_weights('UNetW1.h5')\r\n",
    "\r\n",
    "result = test_train.model.predict(  test_train.validation_data[0]  )\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "r = 1\r\n",
    "#roc, auc\r\n",
    "print(type(result[r]), np.mean(result[r]))\r\n",
    "\r\n",
    "res = (result > 0.175).astype(float)\r\n",
    "print(type(result[r]), np.mean(res[r]))\r\n",
    "\r\n",
    "fig = plt.figure()\r\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\r\n",
    "ax = fig.add_subplot(1,2,1)\r\n",
    "ax.set_title('Ground truth')\r\n",
    "ax.imshow(test_train.validation_data[r][1], cmap='gray')\r\n",
    "\r\n",
    "\r\n",
    "ax1 = fig.add_subplot(1,2,2)\r\n",
    "ax1.set_title('Predicted mask')\r\n",
    "ax1.imshow(res[r], cmap='gray')\r\n",
    "\r\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## GPU TEST"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\r\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.__version__"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import train as tg\r\n",
    "\r\n",
    "def predict_showcase():\r\n",
    "    trainer = tg.Trainer()\r\n",
    "    trainer.load_data()\r\n",
    "    trainer.build_model()\r\n",
    "\r\n",
    "    trainer.model.load_weights('UNetW1.h5')\r\n",
    "\r\n",
    "    result = trainer.model.predict(trainer.validation_data[0])\r\n",
    "\r\n",
    "    return result\r\n",
    "\r\n",
    "def display(result, threshold=0.25):\r\n",
    "    trainer = tg.Trainer()\r\n",
    "    trainer.load_data()\r\n",
    "    r = 1\r\n",
    "    res = (result > threshold).astype(float)\r\n",
    "    print(type(result[r]), np.mean(res[r]))\r\n",
    "\r\n",
    "    fig = plt.figure()\r\n",
    "    fig.subplots_adjust(hspace=0.4, wspace=0.4)\r\n",
    "    ax = fig.add_subplot(1,2,1)\r\n",
    "    ax.set_title('Ground truth')\r\n",
    "    ax.imshow(trainer.validation_data[r][1], cmap='gray')\r\n",
    "\r\n",
    "\r\n",
    "    ax1 = fig.add_subplot(1,2,2)\r\n",
    "    ax1.set_title('Predicted mask')\r\n",
    "    ax1.imshow(res[r], cmap='gray')\r\n",
    "\r\n",
    "    plt.show()\r\n",
    "\r\n",
    "\r\n",
    "result = predict_showcase()\r\n",
    "\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "display(result, 0.175)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from PIL import Image\r\n",
    "x = Image.open(f'src/data/raw_img/ISIC_0000000.jpg').convert(mode='L').resize((512,512))\r\n",
    "y = Image.open(f'src/data/raw_masks/ISIC_0000000_segmentation.png').convert(mode='L').resize((512,512))\r\n",
    "\r\n",
    "x = np.asarray(x.getdata()).reshape(512,512, -1) \r\n",
    "y = np.asarray(y.getdata()).reshape(512,512, -1)\r\n",
    "\r\n",
    "x = x / 255\r\n",
    "y = (y > 0).astype(float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('torch_env': conda)"
  },
  "interpreter": {
   "hash": "4ae8a2da264ef2ff1b1fcc1491c8f0c7d00e17575b69dc2165f5c87ae05d5799"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}